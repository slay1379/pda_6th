# ğŸ–¥ï¸ AWS EC2 ì¸ìŠ¤í„´ìŠ¤ ì„±ëŠ¥ ë¦¬í¬íŠ¸ - Eun-yoo(ì€ìœ )íŒ€
## ğŸš€ ëª©í‘œ
ë‚˜ëŠ” ì£¼ì‹ì„ ì˜ ëª¨ë¥´ëŠ” ì£¼ë¦°ì´ë‹¤.  
ê·¸ë˜ì„œ ì–´ë–¤ ì£¼ì‹ë“¤ì´ ìˆëŠ”ì§€ ì‚´í´ë³´ê³ , ê·¸ ì£¼ì‹ì´ ì˜¤ë¥¼ì§€ ë‚´ë¦´ì§€ë¥¼ ì˜¤ëŠ˜ì˜ ì‚¬íšŒ ì •ì„¸ì— ë”°ë¼ íŒë‹¨í•˜ê³  ì‹¶ë‹¤.  

ë‹¨, ì´ íŒë‹¨ì€ ë‚´ê°€ ì•„ë‹Œ **EC2ì™€ GPTê°€ ëŒ€ì‹  í•œë‹¤**.
<br></br>

## â˜ï¸ í™œìš©í•œ ì¸ìŠ¤í„´ìŠ¤ë“¤
| ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…      | vCPU | ë©”ëª¨ë¦¬   | ì•„í‚¤í…ì²˜ | CPU ì¢…ë¥˜                                                  | íŠ¹ì§•                  |
| ------------ | ---- | ----- | ---- | ------------------------------------------------------- | ------------------- |
| `t4g.micro`  | 2    | 1 GiB | ARM  | AWS Graviton2 (ARM Neoverse N1)                         | ì €ë¹„ìš©, ì—ë„ˆì§€ íš¨ìœ¨, ARM ê¸°ë°˜ |
| `t2.micro`   | 1    | 1 GiB | x86  | Intel Xeon E5-2676 v3 / v4 ë˜ëŠ” AWS ì»¤ìŠ¤í…€ Intel CPU         | ì œí•œì  burst ì„±ëŠ¥, ë¬´ë£Œ í‹°ì–´ |
| `m5.large`   | 2    | 8 GiB | x86  | Intel Xeon Platinum 8175M / 8259CL ë˜ëŠ” AMD EPYC 7000 ì‹œë¦¬ì¦ˆ | ì•ˆì •ì ì¸ ë²”ìš© ì„±ëŠ¥          |
| `c6g.medium` | 1    | 2 GiB | ARM  | AWS Graviton2 (ARM Neoverse N1)                         | ì»´í“¨íŒ… ìµœì í™”, ARM ê¸°ë°˜ ê³ ì„±ëŠ¥ |

<br></br>
## ğŸ“ˆ ì£¼ì œ 1: ìƒì¥ëœ ì£¼ì‹ ì •ë³´ë¥¼ ëª¨ì•„ì„œ ì €ì¥í•´ë³´ì
```python
import pandas as pd
import requests
from bs4 import BeautifulSoup
from io import StringIO
import time
import psutil
import os

# âœ… ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
start_time = time.time()
process = psutil.Process(os.getpid())
cpu_times_start = process.cpu_times()

# âœ… 1. í•œêµ­ê±°ë˜ì†Œ(KRX)ì—ì„œ ì „ì²´ ìƒì¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
def get_krx_stock_list():
    url = "http://kind.krx.co.kr/corpgeneral/corpList.do?method=download"
    res = requests.get(url)
    res.encoding = 'euc-kr'
    data = StringIO(res.text)
    df = pd.read_html(data, header=0)[0]
    df = df[['ì¢…ëª©ì½”ë“œ', 'íšŒì‚¬ëª…']]
    df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].apply(lambda x: f"{x:06d}")
    return df

# âœ… 2. ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì¢…ëª© ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_naver_stock_info(code):
    try:
        url = f"https://finance.naver.com/item/main.nhn?code={code}"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")

        price = soup.select_one("p.no_today span.blind").text.replace(',', '')
        market_cap = soup.select_one("em#_market_sum").text.replace(',', '').replace('ì¡°', '').replace('ì–µì›', '').strip()
        volume = soup.select("table.no_info td")[2].select_one("span.blind").text.replace(',', '')

        return {
            "code": code,
            "price": int(price),
            "market_cap(ì–µ)": float(market_cap),
            "volume": int(volume)
        }
    except Exception:
        return None

# âœ… 3. ì „ì²´ ì¢…ëª© í¬ë¡¤ë§ ì‹¤í–‰
krx_df = get_krx_stock_list()
results = []

print(f"ğŸ“¦ ì „ì²´ ì¢…ëª© ìˆ˜: {len(krx_df)}ê°œ, í¬ë¡¤ë§ ì‹œì‘...\n")

for idx, row in krx_df.iterrows():
    code = row["ì¢…ëª©ì½”ë“œ"]
    name = row["íšŒì‚¬ëª…"]
    info = get_naver_stock_info(code)
    if info:
        info["name"] = name
        results.append(info)

    if idx % 100 == 0:
        print(f"â³ ì§„í–‰ì¤‘... {idx}/{len(krx_df)}")

    time.sleep(0.3)  # ìš”ì²­ ê°„ê²© ì¡°ì ˆ

# âœ… ì„±ëŠ¥ ì¸¡ì • ì¢…ë£Œ
end_time = time.time()
elapsed = end_time - start_time
avg_time = elapsed / len(krx_df)

# âœ… CPU ì‚¬ìš©ë¥  ì¸¡ì • (ì „ì²´ ì‘ì—… ì‹œê°„ ëŒ€ë¹„ CPU ì‚¬ìš© ì‹œê°„ ë¹„ìœ¨)
cpu_times_end = process.cpu_times()
cpu_user_time = cpu_times_end.user - cpu_times_start.user
cpu_system_time = cpu_times_end.system - cpu_times_start.system
cpu_total_time = cpu_user_time + cpu_system_time
cpu_usage_percent = (cpu_total_time / elapsed) * 100  # %

# âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
mem = process.memory_info().rss / (1024 ** 2)  # MB

# âœ… 4. ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥
final_df = pd.DataFrame(results)
final_df = final_df[['name', 'code', 'price', 'market_cap(ì–µ)', 'volume']]

output_file = "krx_analysis_result.csv"
final_df.to_csv(output_file, index=False, encoding='utf-8-sig')

# âœ… ê²°ê³¼ ì¶œë ¥
print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
print("\nğŸ“ˆ ì‹œê°€ì´ì•¡ ê¸°ì¤€ ìƒìœ„ 10ê°œ ì¢…ëª©:")
print(final_df.sort_values(by="market_cap(ì–µ)", ascending=False).head(10).to_string(index=False))

# âœ… ì„±ëŠ¥ ì¶œë ¥
print(f"\nğŸ“Š Performance Summary")
print(f"ğŸ“ˆ Total Execution Time: {elapsed:.2f} sec")
print(f"â±ï¸  Avg Time per Sample: {avg_time:.4f} sec")
print(f"ğŸ“¦ Memory Usage: {mem:.2f} MB")
print(f"âš™ï¸  CPU Usage (estimated over task): {cpu_usage_percent:.2f}%")
```

### ì‹¤í–‰ ê³¼ì •
<img width="461" alt="1  Pandas á„‰á…µá†¯á„’á…¢á†¼ á„€á…ªá„Œá…¥á†¼" src="https://github.com/user-attachments/assets/eb8a7cb2-cb66-4cbd-bd50-83b97251cb00" />

### ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ
<img width="461" alt="1  Pandas á„‰á…µá†¯á„’á…¢á†¼ á„€á…§á†¯á„€á…ª" src="https://github.com/user-attachments/assets/1e233b8a-d11f-4221-af17-feb377691781" />

### ì‹¤í–‰ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
<img width="461" alt="1  Pandas á„€á…§á†¯á„€á…ª á„ƒá…¡á„‹á…®á†«" src="https://github.com/user-attachments/assets/f9d6fea1-998b-40e6-8048-acc835da0d4e" />

### ê·¸ë˜í”„ ë¹„êµ
<table>
  <tr>
    <td align="center"><strong>ì´ ì‹¤í–‰ ì‹œê°„</strong><br><img src="https://github.com/user-attachments/assets/9470132b-08e8-4fab-b366-a3803312fb34" width="400"/></td>
    <td align="center"><strong>ìƒ˜í”Œë‹¹ í‰ê·  ì²˜ë¦¬ ì‹œê°„</strong><br><img src="https://github.com/user-attachments/assets/ab97332e-96be-45bb-885a-2366db19f9c5" width="400"/></td>
  </tr>
  <tr>
    <td align="center"><strong>ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰</strong><br><img src="https://github.com/user-attachments/assets/d45a8a17-868b-47f6-acd8-3bd225f0616c" width="400"/></td>
    <td align="center"><strong>CPU ì‚¬ìš©ë¥ </strong><br><img src="https://github.com/user-attachments/assets/8d2df269-52cf-4e00-86ae-6e6f3e46f13e" width="400"/></td>
  </tr>
</table>

### ğŸ” ì™œ ì´ë ‡ê²Œ ë‚˜ì™”ì„ê¹Œ? ì£¼ì‹ ì •ë³´ëŠ” ë‚´ê°€ ì§ì ‘ ì½ì..
1. ë³‘ë ¬ ì²˜ë¦¬ ì—†ì´ **ìˆœì°¨ì ìœ¼ë¡œ ë™ì‘**
- ì½”ë“œê°€ ì¢…ëª© í•˜ë‚˜ì”© `requests.get()`ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” êµ¬ì¡°ì´ë‹¤.
- ë˜í•œ `time.sleep(0.3)`ìœ¼ë¡œ ìš”ì²­ ê°„ ë”œë ˆì´ê°€ ê³ ì •ë˜ì–´ ìˆì–´, CPU ì„±ëŠ¥ì´ë‚˜ ì½”ì–´ ìˆ˜ê°€ ì¢‹ì•„ë„ **ì†ë„ ê°œì„ ì´ ì–´ë µë‹¤**.

2. ë³‘ëª© êµ¬ê°„ì€ **ë„¤íŠ¸ì›Œí¬ í†µì‹ **
- KRXì™€ ë„¤ì´ë²„ ê¸ˆìœµ ì„œë²„ì— ìš”ì²­ì„ ë³´ë‚´ê³ , ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ì´ ì „ì²´ ì‹¤í–‰ ì‹œê°„ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•œë‹¤.
- ì´ ë„¤íŠ¸ì›Œí¬ ì§€ì—°(latency)ì€ ì¸ìŠ¤í„´ìŠ¤ ì„±ëŠ¥ê³¼ ë¬´ê´€í•˜ê²Œ ì¼ì • ìˆ˜ì¤€ ì´ìƒ ê°œì„ í•˜ê¸° ì–´ë µë‹¤.

3. ëŒ€ë¶€ë¶„ì´ **I/O ì¤‘ì‹¬ ì‘ì—…**
- ì£¼ ì‘ì—…ì€ ê³„ì‚°ì´ ì•„ë‹ˆë¼ **HTTP ìš”ì²­ + HTML íŒŒì‹±**ì´ë‹¤.
- ì—°ì‚°ëŸ‰ì´ ì ê¸° ë•Œë¬¸ì—, `m5.large`ì²˜ëŸ¼ ê³ ì‚¬ì–‘ ì¸ìŠ¤í„´ìŠ¤ë¼ê³  í•´ì„œ ì†ë„ê°€ í¬ê²Œ ë¹¨ë¼ì§€ì§€ ì•ŠëŠ”ë‹¤.

<br></br>
## ğŸ’° ì£¼ì œ 2: ì£¼ì‹ì„ ì˜ˆì¸¡í•´ë³´ì
### ğŸ§  LSTMì´ë€?

LSTM(Long Short-Term Memory)ì€ ê¸°ì–µë ¥ì´ í–¥ìƒëœ RNN(ìˆœí™˜ ì‹ ê²½ë§) êµ¬ì¡°ë¡œ,  
ì…€ ìƒíƒœ(Cell State)ì™€ ê²Œì´íŠ¸(Gate) ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ "ì–´ë–¤ ì •ë³´ë¥¼ ê¸°ì–µí•˜ê³ , ìŠê³ , ì¶œë ¥í• ì§€"ë¥¼ ìŠ¤ìŠ¤ë¡œ ì¡°ì ˆí•œë‹¤.

ğŸ” ì‹œê³„ì—´ ë°ì´í„°ì— ì í•©í•œ ëª¨ë¸ë¡œ,  
ì£¼ê°€ì²˜ëŸ¼ ì‹œê°„ì— ë”°ë¼ ì—°ì†ì ìœ¼ë¡œ ë³€í™”í•˜ëŠ” ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•  ë•Œ ìœ ìš©í•˜ë©°, ê³¼ê±°ì˜ íë¦„ì´ í˜„ì¬ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ë¬¸ì œì— íš¨ê³¼ì ì´ë‹¤.

ğŸ’¡ PyTorchì—ì„œëŠ” `torch.nn.LSTM` ëª¨ë“ˆë¡œ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.

```python
import torch
import torch.nn as nn
import time
import psutil
import os

# âœ… LSTM ëª¨ë¸ ì •ì˜
class SimpleLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(SimpleLSTM, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

# âœ… ëª¨ë¸ & ì…ë ¥ ì¤€ë¹„
model = SimpleLSTM(input_dim=10, hidden_dim=32, output_dim=1)
model.eval()
input_data = torch.randn(1024, 30, 10)  # (batch_size, sequence_length, input_dim)

# âœ… CPU ì‹œê°„ ì¶”ì  ì‹œì‘
process = psutil.Process(os.getpid())
cpu_times_start = process.cpu_times()
start = time.time()

# âœ… ì¶”ë¡  ìˆ˜í–‰
with torch.no_grad():
    output = model(input_data)

# âœ… ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
end = time.time()
elapsed = end - start
avg_time = elapsed / input_data.shape[0]

# âœ… CPU ì‚¬ìš© ì‹œê°„ ê³„ì‚° (user + system)
cpu_times_end = process.cpu_times()
cpu_user_time = cpu_times_end.user - cpu_times_start.user
cpu_system_time = cpu_times_end.system - cpu_times_start.system
cpu_total_time = cpu_user_time + cpu_system_time
cpu_usage_percent = (cpu_total_time / elapsed) * 100 if elapsed > 0 else 0

# âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
mem = process.memory_info().rss / (1024 ** 2)  # in MB

# âœ… ê²°ê³¼ ì¶œë ¥
print(f"ğŸ“ˆ LSTM Inference Time (batch 1024): {elapsed:.2f} sec")
print(f"â±ï¸  Avg Inference per Sample: {avg_time:.4f} sec")
print(f"ğŸ“¦ Memory Usage: {mem:.2f} MB")
print(f"âš™ï¸  CPU Usage (over task): {cpu_usage_percent:.2f}%")
```

### ê·¸ë˜í”„ ë¹„êµ
<table>
  <tr>
    <td align="center"><strong>í‰ê·  ì¶”ë¡  ì‹œê°„<br>(Batch 1024 ê¸°ì¤€)</strong><br>
      <img src="https://github.com/user-attachments/assets/42dfed58-b082-4a46-87ea-d25d7b5a54f4" width="400"/>
    </td>
    <td align="center"><strong>ìƒ˜í”Œë‹¹ í‰ê·  ì¶”ë¡  ì‹œê°„</strong><br>
      <img src="https://github.com/user-attachments/assets/b292b3b9-6a18-4f48-bfe0-e48aa7d387c7" width="400"/>
    </td>
  </tr>
  <tr>
    <td align="center"><strong>í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰</strong><br>
      <img src="https://github.com/user-attachments/assets/d4627c3a-2e4e-40e8-a8a3-f3265fbbd163" width="400"/>
    </td>
    <td align="center"><strong>í‰ê·  CPU ì‚¬ìš©ë¥ </strong><br>
      <img src="https://github.com/user-attachments/assets/4cbd28d3-aafc-4b84-a27c-13d9acd4e8f8" width="400"/>
    </td>
  </tr>
</table>

### ğŸ” ì™œ ì´ë ‡ê²Œ ë‚˜ì™”ì„ê¹Œ? ë¹„ìš©ì´ ì¤‘ìš”í•˜ë©´ t2.micro, ì„±ëŠ¥ì´ ì¤‘ìš”í•˜ë©´ m5.large
1. ê³„ì‚°ëŸ‰ì€ ì‘ì§€ë§Œ **ë²¡í„° ì—°ì‚° ì§‘ì¤‘**
- LSTMì€ ë‚´ë¶€ì ìœ¼ë¡œ `matrix multiplication`, `sigmoid`, `tanh` ë“±ì˜ ì—°ì‚°ì„ ë°˜ë³µí•œë‹¤.
- íŠ¹íˆ `batch_size=1024`ë¡œ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ì–‘ì´ ë§ê¸° ë•Œë¬¸ì—, **ì—°ì‚° ì„±ëŠ¥ì´ ì¢‹ì€ CPUì—ì„œ ì²˜ë¦¬ ì‹œê°„ì´ ë” ì§§ê²Œ** ë‚˜ì˜¨ë‹¤.

2. ARM ê¸°ë°˜ vs x86 ê¸°ë°˜ ì°¨ì´
- `t4g.micro`, `c6g.medium`ì€ **ARM ê¸°ë°˜ Graviton2 í”„ë¡œì„¸ì„œ**ë¥¼ ì‚¬ìš©í•œë‹¤.
- `m5.large`, `t2.micro`ëŠ” **Intel ë˜ëŠ” AMD ê¸°ë°˜ì˜ x86 ì•„í‚¤í…ì²˜**ì´ë‹¤.
- PyTorchëŠ” ë‚´ë¶€ì ìœ¼ë¡œ **x86 ì—°ì‚°ì— ë” ìµœì í™”**ë˜ì–´ ìˆì–´, ARMì—ì„œëŠ” ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦´ ìˆ˜ ìˆë‹¤.
- íŠ¹íˆ `t4g.micro`ëŠ” **ì‘ì€ ì½”ì–´ 2ê°œ**ë§Œ ì œê³µë˜ê¸° ë•Œë¬¸ì— ì—°ì‚° ë„ì¤‘ **CPU ì‚¬ìš©ë¥ ì´ 198%ê¹Œì§€ ì¹˜ì†ŸëŠ”** ëª¨ìŠµì„ ë³´ì˜€ë‹¤.

3. ê³ ì‚¬ì–‘ ì¸ìŠ¤í„´ìŠ¤ì˜ íš¨ê³¼
- `m5.large`ëŠ” 2 vCPUì™€ 8GB RAMì„ ê°€ì§„ **ë²”ìš© ê³ ì„±ëŠ¥ ì¸ìŠ¤í„´ìŠ¤**ì´ë‹¤.
- ê°€ì¥ ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ì™€ ë„‰ë„‰í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë³´ì—¬ì£¼ë©°, **ì—°ì‚° ì¤‘ì‹¬ì˜ ì¶”ë¡  ì‘ì—…ì—ì„œëŠ” ì„±ëŠ¥ ì°¨ì´ê°€ ë¶„ëª…íˆ ì²´ê°**ëœë‹¤.


<br></br>
## ğŸ“° ì£¼ì œ 3: ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ë¥¼ í†µí•´ ì£¼ì‹ ì‹œì¥ íë¦„ì„ íŒŒì•…í•´ë³´ì
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import requests
from bs4 import BeautifulSoup
import time
import psutil
import os

# âœ… ë‰´ìŠ¤ í¬ë¡¤ë§
rss_url = "https://www.yonhapnewstv.co.kr/browse/feed/"
res = requests.get(rss_url)
soup = BeautifulSoup(res.content, 'xml')
articles = [item.find('title').text for item in soup.find_all('item')][:100]
print(f"ğŸ“¥ ë‰´ìŠ¤ ê°œìˆ˜: {len(articles)}")

# âœ… ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ
model_name = "beomi/KcELECTRA-base-v2022"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# âœ… ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
process = psutil.Process(os.getpid())
cpu_times_start = process.cpu_times()
start = time.time()

# âœ… ê°ì • ë¶„ì„ ìˆ˜í–‰
results = classifier(articles)

# âœ… ì„±ëŠ¥ ì¸¡ì • ì¢…ë£Œ
end = time.time()
elapsed = end - start
avg_time = elapsed / len(articles)

# âœ… CPU ì‚¬ìš©ë¥  ê³„ì‚°
cpu_times_end = process.cpu_times()
cpu_user_time = cpu_times_end.user - cpu_times_start.user
cpu_system_time = cpu_times_end.system - cpu_times_start.system
cpu_total_time = cpu_user_time + cpu_system_time
cpu_usage_percent = (cpu_total_time / elapsed) * 100 if elapsed > 0 else 0

# âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
mem = process.memory_info().rss / (1024 ** 2)

# âœ… ê²°ê³¼ ì¶œë ¥
print(f"\nğŸ“° ê°ì„± ë¶„ì„ ì „ì²´ ì‹œê°„: {elapsed:.2f} sec")
print(f"â±ï¸  ë‰´ìŠ¤ 1ê±´ë‹¹ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.4f} sec")
print(f"ğŸ“¦ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem:.2f} MB")
print(f"âš™ï¸  CPU ì‚¬ìš©ë¥  (over task): {cpu_usage_percent:.2f}%")

# âœ… ì˜ˆì‹œ ê²°ê³¼
print("\nğŸ” ì˜ˆì‹œ ê²°ê³¼:")
for i in range(len(articles)):
    label = results[i]['label']
    score = results[i]['score']
    sentiment = "ê¸ì •" if label == "LABEL_1" else "ë¶€ì •"
    print(f"- \"{articles[i]}\" â†’ {sentiment} ({score:.2f})")
```

### ê·¸ë˜í”„ ë¹„êµ
<table>
  <tr>
    <td align="center"><strong>ì „ì²´ ê°ì„± ë¶„ì„ ì²˜ë¦¬ ì‹œê°„</strong><br>
      <img src="https://github.com/user-attachments/assets/911db331-7974-4a64-9327-5722e8cefaf8" width="400"/>
    </td>
    <td align="center"><strong>ë‰´ìŠ¤ 1ê±´ë‹¹ í‰ê·  ë¶„ì„ ì‹œê°„</strong><br>
      <img src="https://github.com/user-attachments/assets/a4dcecd6-a2b5-4c80-9339-a328f1e7d8d3" width="400"/>
    </td>
  </tr>
  <tr>
    <td align="center"><strong>í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰</strong><br>
      <img src="https://github.com/user-attachments/assets/e8544e05-b999-4f96-b8b1-22cc0e2b7ae7" width="400"/>
    </td>
    <td align="center"><strong>í‰ê·  CPU ì‚¬ìš©ë¥ </strong><br>
      <img src="https://github.com/user-attachments/assets/de3b2263-7ca6-4f35-bd69-967c33d3ddee" width="400"/>
    </td>
  </tr>
</table>

### ğŸ” ì™œ ì´ë ‡ê²Œ ë‚˜ì™”ì„ê¹Œ? x86 ê¸°ë°˜ì˜ CPUê°€ ì¢‹ì€ ì¸ìŠ¤í„´ìŠ¤ê°€ ìœ ë¦¬í•˜ë‹¤.

1. ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë”© & ì¶”ë¡ ì€ ë©”ëª¨ë¦¬ ì˜ì¡´ë„ê°€ ë†’ìŒ
- `beomi/KcELECTRA`ëŠ” BERT ê¸°ë°˜ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì´ë‹¤.
- ì•½ **100MB ì´ìƒì˜ ê°€ì¤‘ì¹˜**ì™€ **ë¬¸ì¥ ë‹¨ìœ„ í† í°í™” ì²˜ë¦¬**ê°€ í•„ìš”í•˜ë©°, ì‹¤í–‰ ì‹œ **600~1200MBì˜ ë©”ëª¨ë¦¬ë¥¼ ì ìœ **í•˜ê²Œ ëœë‹¤.
- ë”°ë¼ì„œ RAMì´ ì ì€ ì¸ìŠ¤í„´ìŠ¤ì—ì„œëŠ” ë¡œë”© ë° ì¶”ë¡  ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆë‹¤.

2. CPU ì„±ëŠ¥ì´ í´ìˆ˜ë¡ ë¹ ë¥¸ ì¶”ë¡  ê°€ëŠ¥
- í•´ë‹¹ ì½”ë“œëŠ” **GPU ì—†ì´, CPUë§Œ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ **ì„ ìˆ˜í–‰í•œë‹¤.
- `m5.large`ëŠ” ê³ ì„±ëŠ¥ x86 CPU(2 vCPU)ë¥¼ íƒ‘ì¬í•´ **ê°€ì¥ ë¹ ë¥¸ ì‹œê°„ì— ëª¨ë“  ë‰´ìŠ¤ì˜ ê°ì„± ë¶„ì„ì„ ë§ˆì³¤ë‹¤.**
- ë°˜ë©´, `t2.micro`ëŠ” ëŠë¦° CPUì´ì§€ë§Œ í”„ë¡œì„¸ì„œ ë¶€í•˜ê°€ ë‚®ì•„ **CPU ì‚¬ìš©ë¥ ì´ 68% ìˆ˜ì¤€**ì—ì„œ ë™ì‘í•œë‹¤.
- `t4g.micro`ëŠ” ARM ê¸°ë°˜ ì¸ìŠ¤í„´ìŠ¤ë¡œ, PyTorch ìµœì í™”ê°€ ëœ ë˜ì–´ ìˆì–´ **CPU ì‚¬ìš©ë¥ ì´ 149%ê¹Œì§€ ì¦ê°€**í•˜ë©´ì„œë„ ì¶”ë¡  ì†ë„ëŠ” ì˜¤íˆë ¤ ëŠë ¸ë‹¤.
  
3. ARM vs x86 êµ¬ì¡° ì°¨ì´
- í˜„ì¬ Hugging Face Transformers ë° PyTorchëŠ” **x86 ì•„í‚¤í…ì²˜ì—ì„œ ë” ì•ˆì •ì ì´ê³  ë¹ ë¥´ê²Œ ì‘ë™**í•œë‹¤.
- ë”°ë¼ì„œ ARM ì¸ìŠ¤í„´ìŠ¤ëŠ” ë¹„ìš©ì€ ì €ë ´í•˜ì§€ë§Œ, **CPU ë¶€í•˜ê°€ í¬ê³  ì²˜ë¦¬ ì‹œê°„ì´ ë” ê¸¸ì–´ì§ˆ ìˆ˜ ìˆë‹¤.**
